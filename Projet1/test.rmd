---
title: "R Notebook"
output: html_document
---


```{r}
# install.packages("kableExtra")
# install.packages("tidyverse")
# install.packages("tm")
# install.packages("textclean")
# install.packages("e1071")
# install.packages("caret")
# install.packages("textstem")
```

```{r}
library(kableExtra)  # for table formatting
library(tidyverse)   # for data manipulation
library(tm)          # for text mining
library(textclean)   # for text cleaning
library(e1071)       # for naiveBayes
library(caret)       # for confusionMatrix
library(textstem)
```

```{r}
dataset_path <- "../content/Emotion_classify_Data.csv"
dataset <- read.csv(dataset_path, header = TRUE, sep = ",")
```

---

```{r}
clean_text <- function(text) {
  text <- iconv(text, "UTF-8", "ASCII", sub = " ") # remove caractères spéciaux
  text <- gsub('http\\S+\\s*', "", text) # remove URLs
  text <- gsub('#\\S+', "", text) # remove hashtags
  text <- gsub("[[:digit:]]", "", text) # remove numbers
  text <- textclean::replace_contraction(text) # replace contractions
  text <- gsub(' +', ' ', text) # remove extra whitespaces
  text <- trimws(text)  # remove leading and trailing spaces
  text <- text[text != ""] # remove empty strings
  text <- tolower(text) # to lower case
  return(text)
}
```

```{r}
create_corpus <- function(dataset, clean_text_func, vec_string_methode) {
  corpus <- VCorpus(VectorSource(dataset))
  corpus <- tm_map(corpus, clean_text_func)
  # corpus <- tm_map(corpus, removeWords, stopwords("english"))
  corpus_vec <- tm_map(corpus, vec_string_methode)

  return(corpus_vec)
}

corpus <- create_corpus(dataset, clean_text, lemmatize_strings)
print(corpus$content$Comment[1])
print(corpus$content$Emotion[1])


```
```{r}
create_tfidf <- function(corpus) {
  dtm <- DocumentTermMatrix(corpus$content$Comment)

  terms <- Terms(dtm)
  # print(head(terms))
  corpus_tfidf <- weightTfIdf(dtm)
  corpus_tfidf_df <- as.data.frame(as.matrix(corpus_tfidf))

  inspect(corpus_tfidf)
  return(corpus_tfidf_df)
}


corpus_tfidf_df <- create_tfidf(corpus)
```


```{r}
test_train_split <- function(tfidf_df, raw_data, rate = 0.7, custom.seed = 123) {
  set.seed(custom.seed)

  tfidf_df <- as.data.frame(tfidf_df)
  # Determine the number of rows for the training set
  train_indices <- sample(seq_len(nrow(tfidf_df)), size = rate * nrow(tfidf_df))

  train_commentaire <- tfidf_df[train_indices, ]
  test_commentaire <- tfidf_df[-train_indices, ]

  train_emotion <- raw_data$Emotion[train_indices]
  test_emotion <- raw_data$Emotion[-train_indices]

  return(list(train_set = train_commentaire, train_emotion = train_emotion, test_set = test_commentaire, test_emotion = test_emotion))
}

custom_dataset <- test_train_split(corpus_tfidf_df, dataset)
train_commentaire <- custom_dataset[1]
train_emotion <- custom_dataset[2]
test_commentaire <- custom_dataset[3]
test_emotion <- custom_dataset[4]
```
```{r}
# model <- naiveBayes(train_commentaire, train_emotion)
model <- naiveBayes(as.matrix(train_commentaire), train_emotion)
predictions <- predict(model, as.matrix(test_commentaire))
```
---

```{r}
cm <- confusionMatrix(predictions, as.factor(test_emotion))

# Extract the accuracy, precision, recall, and F1-score
# accuracy <- cm$overall['Accuracy']
# precision <- cm$byClass['Pos Pred Value']
# recall <- cm$byClass['Sensitivity']
# F1 <- 2 * (precision * recall) / (precision + recall)

# # Print the results
# print(paste("Accuracy: ", accuracy))
# print(paste("Precision: ", precision))
# print(paste("Recall: ", recall))
# print(paste("F1 Score: ", F1))

print(cm)
```

```{r}
# predictions <- predict(model, data.frame(Comment = "No ! It's false, he'd make shit"))
# predictions <- predict(model, data.frame(Comment = "Yes it is lovely"))
predictions <- predict(model, data.frame(Comment = "I am not sure about that, I think it is dangerous"))
predictions
```